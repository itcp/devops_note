启动顺序 zookeeper -> kafka -> elasticsearch -> filebeat -> logstash -> kibana

------

# kafka

先启动zookeeper

```
/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties > /data/logs/zookeeper/zk.log 2>&1 &
```

再启动 kafka

```
/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties > /data/logs/kafka/kafka.log 2>&1 &
```

停止

```
/usr/local/kafka/bin/kafka-server-stop.sh
/usr/local/kafka/bin/zookeeper-server-stop.sh
```

日志：

/data/logs/zookeeper/zk.log

/data/logs/kafka/kafka.log

调试

```
查看 topic 信息列表
kafka-topics.sh --zookeeper 10.70.116.168:2181,10.70.116.178:2181 --list

创建topic
kafka-topics.sh --create --zookeeper 10.70.116.168:2181,10.70.116.178:2181 --replication-factor 1 --partitions 2 --topic mytopic

# --replication-factor 1 副本只留一个
# --partitions 2 消息者的数据
# --topic mytopic 指定 topic的名字


查看这 mytopic的详细信息
kafka-topics.sh --describe --zookeeper 10.70.116.168:2181,10.70.116.178:2181 --topic mytopic

生产消息
kafka-console-producer.sh --broker-list 10.70.116.168:9092,10.70.116.178:9092 --topic mytopic
回车后输入你的消息文本


消费消息
kafka-console-consumer.sh --bootstrap-server 10.70.116.182:9092 --topic system_log
这是一边生产一边消费的



如果要看到所有的消息，加 --from-beginning 是从头消费
kafka-console-consumer.sh --bootstrap-server 10.70.116.182:9092 --topic system_log --from-beginning

删除topic
kafka-topics.sh --zookeeper 10.70.116.168:2181,10.70.116.178:2181 --delete --topic mytopic
```

------

# elasticsearch

systemctl status | start | stop elasticsearch

运行日志：/data/es-log

数据目录：/data/es-data

------

# filebeat 

systemctl status | start | stop filebeat

运行日志：/usr/local/filebeat/logs   # 有错误时才会有日志

------

# logstash

启动 

/usr/local/logstash/bin/logstash -f /usr/local/logstash/config/logstash.conf > /data/logs/logstash/logstash.log 2>&1 &

停止 ，先 找到 pid，kill -9 掉

ps aux | grep logstash

kill -9 xxxx

运行日志： /data/logs/logstash/logstash.log

------

# kibana

`systemctl status | start | stop kibana`

------



# elasticsearch 的使用



索引与分片,elasticsearch默认是1000个分片上限，但一个索引如果按一般默认的副本数为5的话，就要1个索引使用5个分片。

在你单个索引的数据量小时，最好是减少分片数，不然后面分片数用完了。elasticsearch会不能创建新的索引而无法写入数据。

在你后期单个索引的数据量大时，多大呢？按一个分片数据不能大于32G，这是jvm的一种限制。就要增加这个索引的分片数。



## 日志源的收集注意

- 日志格式能为json的最好

- 日志打印能通过网络存到队列（kafka）的最好，不用写入到本地文件再filebeat收集一遍，能减少IO。不过要开发者打印 时自定义好格式。
- 在日志源打印的日志最有时间属性为datetime格式并且是UTC时区，到logstash就可以少了时间的处理



修改设置默认索引为 2个分片，1个备份副本

curl -XPUT 'http://172.18.111.185:9200/_template/template_http_request_record' -H 'Content-Type: application/json' -d '{"index_patterns": ["*"], "settings": { "number_of_shards" : 2, "number_of_replicas" : 1 }}'



查看索引模板

curl -XPUT 'https://vpc-log-service-3z7zzgdja2trow5ivyblagazgi.ap-northeast-1.es.amazonaws.com/_template/template_http_request_record' \
-H 'Content-Type: application/json' -d '{"index_patterns": ["*"], "settings": { "number_of_shards" : 2, "number_of_replicas" : 1 }}'

